{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from helpers import *\n",
    "from implementations import *\n",
    "from data_processing import *\n",
    "from hyperparams import *\n",
    "\n",
    "from classification import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some functions used below\n",
    "\n",
    "def get_only_accuracy(y_result, y_te):\n",
    "    difference = (y_result-y_te)\n",
    "    good_guess = difference[difference==0]\n",
    "    bad_guess = difference[difference!=0]\n",
    "    accuracy = len(good_guess)/(len(good_guess)+len(bad_guess))\n",
    "    return accuracy\n",
    "\n",
    "def standardize(x):\n",
    "    X = np.copy(x)\n",
    "    means = np.mean(X, axis=0)\n",
    "    tx_new = X - means * np.ones(np.shape(X))\n",
    "    std_dev = np.std(tx_new, axis=0)\n",
    "    X = tx_new / (std_dev * np.ones(np.shape(X)))\n",
    "    return X, means, std_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading/splitting train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading train data\n",
    "yb, input_data, ids = load_csv_data(\"train.csv\")\n",
    "dimensions = np.shape(input_data)\n",
    "N = dimensions[0]\n",
    "P = dimensions[1]\n",
    "yb = np.reshape(yb,[N,1])\n",
    "yb[yb==-1] = 0 # adapting to our logistic loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data_replace(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr, x_tr, y_te, x_te = split_data(yb,x,0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling case 1\n",
    "\n",
    "It is immediately noticeable that this method is completely incorrect: the -999 values and others that are too high make the exponential terms overflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/toye/Desktop/ML1_final/implementations.py:229: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-t))\n",
      "/Users/toye/Desktop/ML1_final/implementations.py:246: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -(1/len(y)) * ( y.T @ np.log(sigmoid(tx@w)) + (1-y).T @ np.log(1-sigmoid(tx@w)) )\n",
      "/Users/toye/Desktop/ML1_final/implementations.py:246: RuntimeWarning: invalid value encountered in matmul\n",
      "  loss = -(1/len(y)) * ( y.T @ np.log(sigmoid(tx@w)) + (1-y).T @ np.log(1-sigmoid(tx@w)) )\n"
     ]
    }
   ],
   "source": [
    "x1 = np.copy(x)\n",
    "initial_w = np.ones([P,1])\n",
    "max_iters = 100\n",
    "gamma = 0.7\n",
    "w_opt_1, mse = logistic_regression(yb, x1, initial_w, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling case 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = np.copy(x_tr)\n",
    "\n",
    "x2, means2, std_dev2 = standardize(x2)\n",
    "\n",
    "initial_w = np.zeros([P,1])\n",
    "max_iters = 100\n",
    "gamma = 0.7\n",
    "w_opt_2, mse = logistic_regression(y_tr, x2, initial_w, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_new = np.copy(x_te)\n",
    "mean_te_2 = np.mean(tx_new)\n",
    "std_te_2 = np.std(tx_new)\n",
    "tx_new = tx_new - mean_te_2\n",
    "x_te_2 = tx_new / std_te_2  \n",
    "\n",
    "temporary = sigmoid(x_te_2@w_opt_2)\n",
    "y_result = temporary\n",
    "y_result[y_result>0.5] = 1\n",
    "y_result[y_result<0.5] = 0\n",
    "accuracy2 = get_only_accuracy(y_result, y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46056"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3 = np.copy(x_tr)\n",
    "x3, means3, std_dev3 = standardize(x3)\n",
    "x3 = add_w0(x3,x3.shape[0])\n",
    "\n",
    "initial_w = np.zeros([P+1,1])\n",
    "max_iters = 100\n",
    "gamma = 0.7\n",
    "w_opt_3, mse = logistic_regression(y_tr, x3, initial_w, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_new = x_te - means3\n",
    "x_te_3 = tx_new / std_dev3  \n",
    "x_te_3 = add_w0(x_te, x_te_3.shape[0])\n",
    "\n",
    "temporary = sigmoid(x_te_3@w_opt_3)\n",
    "\n",
    "y_result = temporary\n",
    "y_result[y_result>0.5] = 1\n",
    "y_result[y_result<0.5] = 0\n",
    "accuracy3 = get_only_accuracy(y_result, y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52396"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x4 = np.copy(x_tr)\n",
    "indices_min_max =[3,11,12,22,26]\n",
    "indices_gaussian =[0,1,6,8,13,14,16,17,24,27]\n",
    "indices_angles = [15,18,20,25,28]\n",
    "indices_gaussian_log = [2,5,7,9,10,19]\n",
    "normalize(x4, indices_gaussian_log, indices_angles, indices_gaussian, indices_min_max)\n",
    "x4= add_w0(x4,x4.shape[0])\n",
    "\n",
    "initial_w = np.zeros([P+1,1])\n",
    "max_iters = 100\n",
    "gamma = 0.7\n",
    "w_opt_4, mse = logistic_regression(y_tr, x4, initial_w, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_te_4 = np.copy(x_te)\n",
    "normalize(x_te_4, indices_gaussian_log, indices_angles, indices_gaussian, indices_min_max)\n",
    "x_te_4 = add_w0(x_te_4,x_te_4.shape[0])\n",
    "\n",
    "temporary = sigmoid(x_te_4@w_opt_4)\n",
    "y_result = temporary\n",
    "y_result[y_result>0.5] = 1\n",
    "y_result[y_result<0.5] = 0\n",
    "accuracy4 = get_only_accuracy(y_result, y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34424"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x5 = np.copy(x_tr)\n",
    "indices_min_max =[3,11,12,22,26]\n",
    "indices_gaussian =[0,1,6,8,13,14,16,17,24,27]\n",
    "indices_angles = [15,18,20,25,28]\n",
    "indices_gaussian_log = [2,5,7,9,10,19]\n",
    "normalize(x5, indices_gaussian_log, indices_angles, indices_gaussian, indices_min_max)\n",
    "x5 = np.delete(x5,29,1)\n",
    "x5 = np.delete(x5,23,1)\n",
    "x5 = np.delete(x5,22,1)\n",
    "x5 = np.delete(x5,21,1)\n",
    "x5 = np.delete(x5,4,1)\n",
    "x5= add_w0(x5, x5.shape[0])\n",
    "\n",
    "\n",
    "initial_w = np.zeros([P-4,1])\n",
    "max_iters = 100\n",
    "gamma = 0.7\n",
    "w_opt_5, mse = logistic_regression(y_tr, x5, initial_w, max_iters, gamma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_te_5 = np.copy(x_te)\n",
    "normalize(x_te_5, indices_gaussian_log, indices_angles, indices_gaussian, indices_min_max)\n",
    "x_te_5 = np.delete(x_te_5,29,1)\n",
    "x_te_5 = np.delete(x_te_5,23,1)\n",
    "x_te_5 = np.delete(x_te_5,22,1)\n",
    "x_te_5 = np.delete(x_te_5,21,1)\n",
    "x_te_5 = np.delete(x_te_5,4,1)\n",
    "x_te_5= add_w0(x_te_5,x_te_5.shape[0])\n",
    "\n",
    "temporary = sigmoid(x_te_5@w_opt_5)\n",
    "y_result = temporary\n",
    "y_result[y_result>0.5] = 1\n",
    "y_result[y_result<0.5] = 0\n",
    "accuracy5 = get_only_accuracy(y_result, y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7431"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(y_results, y_te, score):\n",
    "    \"\"\"Checks whether prediction are accurate by compraing with y_te\n",
    "    \n",
    "    Args: \n",
    "        predictions:\n",
    "        y_te:\n",
    "    \n",
    "    Returns:\n",
    "        len(good_guess):\n",
    "        len(bad_guess):\n",
    "    \"\"\" \n",
    "    \n",
    "    difference = (y_results-y_te)\n",
    "    good_guess = difference[difference==0]\n",
    "    bad_guess = difference[difference!=0]\n",
    "    accuracy = len(good_guess)/(len(good_guess)+len(bad_guess))\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    \n",
    "    for i in range(y_results.shape[0]):\n",
    "        if difference[i] == 1:\n",
    "            FP +=1\n",
    "        if difference[i] == -1:\n",
    "            FN +=1\n",
    "        else :\n",
    "            if y_results[i] == 1:\n",
    "                TP +=1\n",
    "            else:\n",
    "                TN +=1       \n",
    "                \n",
    "    precision = TP/(TP+FP)  \n",
    "    recall = TP/(TP+FN)\n",
    "    auc = get_auc(score, y_te)\n",
    "    #print(f\"How well our model can classify binary outcomes: accuracy of {accuracy}, precision of {precision}, and recall of {recall}\")\n",
    "    print(\"How well our model can classify binary outcomes: accuracy of %.3f, precision of %.3f, recall of %.3f, and AUC score of %.3f\" % (accuracy, precision, recall, auc))\n",
    "    \n",
    "    return accuracy, precision, recall\n",
    "\n",
    "\n",
    "def get_auc(score, y_results):\n",
    "\n",
    "    y = y_results\n",
    "\n",
    "    # false positive rate\n",
    "    FPR = []\n",
    "    # true positive rate\n",
    "    TPR = []\n",
    "    # Iterate thresholds from 0.0 to 1.0\n",
    "    thresholds = np.arange(0.0, 1.01, 0.001)\n",
    "    print(len(thresholds))\n",
    "\n",
    "    # get number of positive and negative examples in the dataset\n",
    "    P = sum(y)\n",
    "    N = len(y) - P\n",
    "\n",
    "    # iterate through all thresholds and determine fraction of true positives\n",
    "    # and false positives found at this threshold\n",
    "    for thresh in thresholds:\n",
    "        FP=0\n",
    "        TP=0\n",
    "        thresh = round(thresh,2) \n",
    "        for i in range(len(score)):\n",
    "            if (score[i] >= thresh):\n",
    "                if y[i] == 1:\n",
    "                    TP += 1\n",
    "                if y[i] == 0:\n",
    "                    FP += 1            \n",
    "        FPR = np.append(FPR,FP/N)\n",
    "        TPR = np.append(TPR, TP/P)\n",
    "\n",
    "    #computing Arean Under Curve using the trapezoidal method\n",
    "    auc = -1 * np.trapz(TPR, x=FPR)\n",
    "    print(auc)\n",
    "\n",
    "    \n",
    "    plt.plot(FPR, TPR, marker='.', color='darkorange', label='ROC curve', clip_on=False)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', linestyle='--', label = 'No Discrimination')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.title('ROC curve, AUC = %.2f'%auc)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "    plt.savefig('AUC_example.png')\n",
    "    plt.show()\n",
    "    \n",
    "    return auc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d597f4c481aa0f25dceb95d2a0067e73c0966dcbd003d741d821a7208527ecf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
