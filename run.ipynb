{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fee6f6b0-1331-4f6b-a386-2e00d9036945",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from helpers import *\n",
    "from implementations import *\n",
    "from data_processing import *\n",
    "from hyperparams import *\n",
    "# from classification import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3049ab19",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload # run this when want to update changes in a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "218600e2-5d34-4bc0-ad81-322fd83a5730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading train data (takes 10 secs, avoid spamming cell)\n",
    "yb, input_data, ids = load_csv_data(\"train.csv\")\n",
    "dimensions = np.shape(input_data)\n",
    "N = dimensions[0]\n",
    "P = dimensions[1]\n",
    "yb = np.reshape(yb,[N,1])\n",
    "yb[yb==-1] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22d3083f-fad1-4cbe-80b2-df26482809a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize data without the incomplete points, calculations done on _rem arrays (with -999 lines removed)\n",
    "y_rem, tx_rem_std = standardize_data_removed(yb,input_data)\n",
    "tx_means_std = standardize_data_mean(input_data)\n",
    "\n",
    "tx_rem_std = add_w0(tx_rem_std,tx_rem_std.shape[0])   \n",
    "tx_means_std = add_w0(tx_means_std,N)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d0712f5-6168-4719-86ef-728fedc4a0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_reduced = tx_rem_std[range(1000),:]  # 100x30 data for faster testing of regression\n",
    "y_reduced = yb[0:1000]\n",
    "ratio = 0.8\n",
    "\n",
    "y_tr, x_tr, y_te, x_te = split_data(y_reduced,tx_reduced,ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25f899e9-73ff-4738-99ec-61dadb12f65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_w = np.zeros([31,1])   \n",
    "max_iters = 50\n",
    "gamma = 0.4\n",
    "w_opt,loss = logistic_regression(y_tr,x_tr,initial_w,max_iters,gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca145c81-a329-46cc-9f5a-1c53eaf24d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6344047781132445\n"
     ]
    }
   ],
   "source": [
    "np.shape(initial_w)\n",
    "np.shape(w_opt)\n",
    "print(loss)              #\"PROBLEM nan\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de1a171",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_elements = 1000\n",
    "\n",
    "for i in range(number_of_elements):\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    best_lambda, best_rmse = cross_validation_demo(y_reduced, tx_reduced, 7, 4, initial_w,  np.logspace(-4, 0, 30), 3 ,gamma, max_iters)\n",
    "    print(best_rmse)#Here should be the code that does the computation.\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb71baa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the matrix with the polynomial expansion for each column\n",
    "size_x_tr = x_tr.shape[0]\n",
    "gamma = 0.4 #Quite low to avoid NaN\n",
    "lambdas = np.logspace(-2, -1.8, 20) #the lambda tested for the logistic regression, for each lambda we test each degree\n",
    "initial_w = np.ones([size_x_tr,1])\n",
    "max_iters = 20\n",
    "degrees_tested = [1,2,3,5,6,8] #the degrees tested for the polynoms\n",
    "phi, degrees_poly =phi_optimized(y_tr,x_tr,degrees_tested,P, 4, initial_w, lambdas, gamma,max_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6877ba7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6c4a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_size = np.sum(degrees_poly)  +1  #size of the new input data \n",
    "initial_w = np.ones([new_size,1]) \n",
    "best_lambda, best_rmse = cross_validation_demo(y_tr, phi, 7, 4,initial_w,  np.logspace(-4, 0, 30), 3 ,gamma, max_iters ) #test for the best lambda, in the matrix expanded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3055263",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the weights for the best lambda, with the train data\n",
    "gamma = 0.2\n",
    "w_opt,loss = reg_logistic_regression(y_tr, phi, best_lambda, initial_w, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab22fe44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A FAIRE: Tester pr√©diction (quand on n'aura plus le NaN)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
