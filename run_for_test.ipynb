{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fee6f6b0-1331-4f6b-a386-2e00d9036945",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from helpers import *\n",
    "from implementations import *\n",
    "from data_processing import *\n",
    "from hyperparams import *\n",
    "# from classification import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "218600e2-5d34-4bc0-ad81-322fd83a5730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading train data \n",
    "yb, input_data, ids = load_csv_data(\"train.csv\")\n",
    "dimensions = np.shape(input_data)\n",
    "N = dimensions[0]\n",
    "P = dimensions[1]\n",
    "yb = np.reshape(yb,[N,1])\n",
    "yb[yb==-1] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dab5ede4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace missing data by median if more than half of the data is missing, or mean if less\n",
    "tx = data_replace(input_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "996eec94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/toye/Desktop/ML1_final/implementations.py:229: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-t))\n",
      "/Users/toye/Desktop/ML1_final/implementations.py:246: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -(1/len(y)) * ( y.T @ np.log(sigmoid(tx@w)) + (1-y).T @ np.log(1-sigmoid(tx@w)) )\n",
      "/Users/toye/Desktop/ML1_final/implementations.py:246: RuntimeWarning: invalid value encountered in matmul\n",
      "  loss = -(1/len(y)) * ( y.T @ np.log(sigmoid(tx@w)) + (1-y).T @ np.log(1-sigmoid(tx@w)) )\n"
     ]
    }
   ],
   "source": [
    "#Create polynoms\n",
    "# Construct the matrix with the polynomial expansion for each column\n",
    "size_x_tr = tx.shape[0]\n",
    "gamma = 0.4 #Quite low to avoid NaN\n",
    "lambdas = np.logspace(-4, -1.8, 20) #the lambda tested for the logistic regression, for each lambda we test each degree\n",
    "initial_w = np.ones([size_x_tr,1])\n",
    "max_iters = 20\n",
    "degrees_tested = [1,2,3,4,5] #the degrees tested for the polynoms\n",
    "columns_to_expand = [2,3,5,6,7,8,9,10,11,12,13,14,16,17,19,22,24,25,26,27,28]#[1,2,3,5,6,7,8,9,10,11,12,13,14,16,17,19,22,24,25,26,27,28] #enlever : 1\n",
    "phi, degrees_poly = phi_optimized(yb,tx,degrees_tested,P, 4, initial_w, lambdas, gamma,max_iters,columns_to_expand)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6ca904",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize each feature according to its type of distribution\n",
    "\n",
    "indices_min_max =[3,11,12,22,26]\n",
    "indices_gaussian =[0,1,6,8,13,14,16,17,24,27]\n",
    "indices_angles = [15,18,20,25,28]\n",
    "indices_gaussian_log = [2,5,7,9,10,19]\n",
    "\n",
    "normalize (phi, indices_gaussian_log, indices_angles, indices_gaussian, indices_min_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41225383",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Normalize the polynoms according to their min and max (rescaling)\n",
    "\n",
    "for x in range(29,phi.shape[1]) :\n",
    "     c = phi[:,x]\n",
    "     min = np.min(c, axis=0)\n",
    "     max = np.max(c, axis=0)\n",
    "     phi[:,x] = (c-min) / (max-min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33bfb28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 66)\n"
     ]
    }
   ],
   "source": [
    "#Add dummy variables instead of the categorical (feature PRI jet num)\n",
    "\n",
    "nb_indice = phi.shape[1]\n",
    "new_col = np.zeros([phi.shape[0],4])\n",
    "phi = np.c_[phi, new_col]\n",
    "print(phi.shape)\n",
    "for i in range(phi.shape[0]) : \n",
    "    if (phi[i,22] == 0) : \n",
    "        phi[i,nb_indice] = 1\n",
    "    if (phi[i,22] == 1) : \n",
    "        phi[i,nb_indice +1] = 1\n",
    "    if (phi[i,22] == 2) : \n",
    "        phi[i,nb_indice +2] = 1\n",
    "    if (phi[i,22] == 3) : \n",
    "        phi[i,nb_indice +3] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6923787",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deleted features correlated more than 85% with another feature, and PRI jet num\n",
    "\n",
    "phi = np.delete(phi,29,1)\n",
    "phi = np.delete(phi,23,1)\n",
    "phi = np.delete(phi,22,1)\n",
    "phi = np.delete(phi,21,1)\n",
    "phi = np.delete(phi,4,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d683eded",
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = add_w0(phi,phi.shape[0])   \n",
    "\n",
    "#Choose a subset to train\n",
    "\n",
    "\"\"\"tx_reduced = (phi[range(200000),:])  # 100x30 data for faster testing of regression\n",
    "y_reduced = (y_new[range(200000)])\n",
    "ratio = 0.8\"\"\"\n",
    "\n",
    "#Split into train and test data\n",
    "#y_tr, x_tr, y_te, x_te = split_data(y_reduced,tx_reduced,ratio)\n",
    "\n",
    "#Train on the whole data \n",
    "x_tr = phi\n",
    "y_tr = yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4200d98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic regression\n",
    "initial_w = np.zeros([x_tr.shape[1],1])   \n",
    "max_iters = 1000\n",
    "gamma = 0.5\n",
    "w_opt,loss = logistic_regression(y_tr,x_tr,initial_w,max_iters,gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c801fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "(62, 1)\n"
     ]
    }
   ],
   "source": [
    "print(loss)\n",
    "print(w_opt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c8d4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If want to do reg logistic regression\n",
    "\n",
    "#Calculate best lambda with cross validation\n",
    "\n",
    "\"\"\"initial_w = np.ones([x_tr.shape[1],1])\n",
    "max_iters = 200\n",
    "best_lambda, best_rmse = cross_validation_demo(y_tr, x_tr, 7, 4,initial_w,  np.logspace(-8, 0, 30), 3 ,gamma, max_iters )\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7c0184",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate reg logistic regression\n",
    "#w_opt2,loss2 = reg_logistic_regression(y_tr, x_tr, best_lambda, initial_w, max_iters, gamma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee746ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Processing test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60414304",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test, x_test, ids = load_csv_data(\"test.csv\")\n",
    "dimensions_te = np.shape(x_test)\n",
    "N = dimensions_te[0]\n",
    "P = dimensions_te[1]\n",
    "y_test = np.reshape(y_test,[N,1])\n",
    "y_test[y_test==-1] = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804c0c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace by mean/median\n",
    "\n",
    "x_te = data_replace(x_test)\n",
    "y_te = y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ff97e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build same polynoms than train data\n",
    "columns_to_expand = [2,3,5,6,7,8,9,10,11,12,13,14,16,17,19,22,24,25,26,27,28]\n",
    "i = 0\n",
    "for column in columns_to_expand : \n",
    "    if (degrees_poly[i] > 1) : \n",
    "        poly_x = build_poly(x_te[:,column], degrees_poly[i])\n",
    "        x_te = np.c_[x_te, poly_x ]\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09069495",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize each feature according to its type of distribution\n",
    "\n",
    "indices_min_max =[3,11,12,22,26]\n",
    "indices_gaussian =[0,1,6,8,13,14,16,17,24,27]\n",
    "indices_angles = [15,18,20,25,28]\n",
    "indices_gaussian_log = [2,5,7,9,10,19]\n",
    "\n",
    "normalize (x_te, indices_gaussian_log, indices_angles, indices_gaussian, indices_min_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7363c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize polynoms\n",
    "for x in range(29,x_te.shape[1]) :\n",
    "     c = x_te[:,x]\n",
    "     min = np.min(c, axis=0)\n",
    "     max = np.max(c, axis=0)\n",
    "     x_te[:,x] = (c-min) / (max-min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b378f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add dummy variables instead of the categorical (feature PRI jet num)\n",
    "\n",
    "nb_indice = x_te.shape[1]\n",
    "new_col = np.zeros([x_te.shape[0],4])\n",
    "x_te = np.c_[x_te, new_col]\n",
    "print(phi.shape)\n",
    "for i in range(x_te.shape[0]) : \n",
    "    if (x_te[i,22] == 0) : \n",
    "        x_te[i,nb_indice] = 1\n",
    "    if (x_te[i,22] == 1) : \n",
    "        x_te[i,nb_indice +1] = 1\n",
    "    if (x_te[i,22] == 2) : \n",
    "        x_te[i,nb_indice +2] = 1\n",
    "    if (x_te[i,22] == 3) : \n",
    "        x_te[i,nb_indice +3] = 1\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d89cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deleted features correlated more than 85% with another feature, and PRI jet num\n",
    "\n",
    "x_te = np.delete(x_te,29,1)\n",
    "x_te = np.delete(x_te,23,1)\n",
    "x_te = np.delete(x_te,22,1)\n",
    "x_te = np.delete(x_te,21,1)\n",
    "x_te = np.delete(x_te,4,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d7faae",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_te= add_w0(x_te,x_te.shape[0])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e44b849",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = sigmoid(x_te@w_opt)\n",
    "y_pred[y_pred>0.5] = 1\n",
    "y_pred[y_pred<0.5] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbd9bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv_submission(ids, y_pred, \"predictions\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "3d597f4c481aa0f25dceb95d2a0067e73c0966dcbd003d741d821a7208527ecf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
